---
title: Fraud Detection Using Large-scale Imbalance Dataset
publication_types:
  - article-journal
authors:
  - boulbaba-ben-ammar
  - admin
doi: https://doi.org/10.1142/S0218213022500373
abstract: "In the context of machine learning, an imbalanced classification
  problem states to a dataset in which the classes are not evenly distributed.
  This problem commonly occurs when attempting to classify data in which the
  distribution of labels or classes is not uniform. Using resampling methods to
  accumulate samples or entries from the minority class or to drop those from
  the majority class can be considered the best solution to this problem. The
  focus of this study is to propose a framework pattern to handle any imbalance
  dataset for fraud detection. For this purpose, Undersampling (Random and
  NearMiss) and oversampling (Random, SMOTE, BorderLine SMOTE) were used as
  resampling techniques for the concentration of our experiments for balancing
  an evaluated dataset. For the first time, a large-scale unbalanced dataset
  collected from the Kaggle website was used to test both methods for detecting
  fraud in the Tunisian company for electricity and gas consumption. It was also
  evaluated with four machine learning classifiers: Logistic Regression (LR),
  Na√Øve Bayes (NB), Random Forest, and XGBoost. Standard evaluation metrics like
  precision, recall, F1-score, and accuracy have been used to assess the
  findings. The experimental results clearly revealed that the RF model provided
  the best performance and outperformed all other matched classifiers with
  attained a classification accuracy of 89% using NearMiss undersampling and 99%
  using Random oversampling."
draft: false
featured: false
tags:
  - Fraud detection
  - classification
  - machine learning
  - oversampling
  - undersampling
image:
  filename: featured
  focal_point: Smart
  preview_only: false
date: 2022-09-16T16:51:55.307Z
url_pdf: https://www.worldscientific.com/doi/pdf/10.1142/S0218213022500373?download=true
---
